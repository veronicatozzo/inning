{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from six.moves import reload_module as reload\n",
    "from sklearn.utils.extmath import fast_logdet\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import make_sparse_spd_matrix\n",
    "from sklearn.covariance import empirical_covariance\n",
    "from functools import partial\n",
    "\n",
    "from network_inference.prox import prox_logdet, soft_thresholding_od\n",
    "import network_inference.datasets; reload(network_inference.datasets)\n",
    "from network_inference.datasets import is_pos_def, is_pos_semi_def\n",
    "from network_inference.utils import _scalar_product, update_rho, convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random_state=0\n",
    "A = make_sparse_spd_matrix(dim=15, alpha=0.7, random_state=random_state)\n",
    "\n",
    "T_true = A[5:,5:]\n",
    "K_true = A[10:,5:,]\n",
    "H_true = A[0:5,0:5]\n",
    "\n",
    "per_cov = K_true*0.3\n",
    "T_obs = T_true - per_cov.T.dot(np.linalg.inv(H_true)).dot(per_cov)\n",
    "assert is_pos_def(T_obs)\n",
    "samples = np.random.multivariate_normal(np.zeros(10), np.linalg.inv(T_obs), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = np.random.rand(10,10)\n",
    "H = H.T.dot(H)\n",
    "is_pos_def(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KHK = K_true.dot(np.linalg.inv(H)).dot(K_true.T)\n",
    "is_pos_semi_def(KHK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.random.rand(10,10)\n",
    "B = (B + B.T)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.11816965 0.45474709 0.5010573  0.36805558 0.63574256 0.52032664\n",
      "  0.41072931 0.48340038 0.41708394 0.37812795]\n",
      " [0.45474709 0.8866356  0.57266548 0.51233908 0.24489252 0.48577112\n",
      "  0.46281713 0.45007783 0.39217987 0.5739606 ]\n",
      " [0.5010573  0.57266548 1.28331493 0.60546084 0.59111138 0.40688912\n",
      "  0.78700844 0.73639315 0.50965012 0.44175215]\n",
      " [0.36805558 0.51233908 0.60546084 0.89636091 0.26163205 0.3997368\n",
      "  0.32251138 0.3882654  0.49226217 0.48038112]\n",
      " [0.63574256 0.24489252 0.59111138 0.26163205 0.75632349 0.35922301\n",
      "  0.48396987 0.4438248  0.36876735 0.27045707]\n",
      " [0.52032664 0.48577112 0.40688912 0.3997368  0.35922301 0.99055032\n",
      "  0.43717534 0.4406951  0.3592805  0.13538478]\n",
      " [0.41072931 0.46281713 0.78700844 0.32251138 0.48396987 0.43717534\n",
      "  1.1842511  0.63884983 0.46005749 0.39684808]\n",
      " [0.48340038 0.45007783 0.73639315 0.3882654  0.4438248  0.4406951\n",
      "  0.63884983 1.02853077 0.18347819 0.24403319]\n",
      " [0.41708394 0.39217987 0.50965012 0.49226217 0.36876735 0.3592805\n",
      "  0.46005749 0.18347819 0.90332919 0.42814801]\n",
      " [0.37812795 0.5739606  0.44175215 0.48038112 0.27045707 0.13538478\n",
      "  0.39684808 0.24403319 0.42814801 0.8597387 ]] [[1.11816965 0.45474709 0.5010573  0.36805558 0.63574256 0.52032664\n",
      "  0.41072931 0.48340038 0.41708394 0.37812795]\n",
      " [0.45474709 0.8866356  0.57266548 0.51233908 0.24489252 0.48577112\n",
      "  0.46281713 0.45007783 0.39217987 0.5739606 ]\n",
      " [0.5010573  0.57266548 1.28331493 0.60546084 0.59111138 0.40688912\n",
      "  0.78700844 0.73639315 0.50965012 0.44175215]\n",
      " [0.36805558 0.51233908 0.60546084 0.89636091 0.26163205 0.3997368\n",
      "  0.32251138 0.3882654  0.49226217 0.48038112]\n",
      " [0.63574256 0.24489252 0.59111138 0.26163205 0.75632349 0.35922301\n",
      "  0.48396987 0.4438248  0.36876735 0.27045707]\n",
      " [0.52032664 0.48577112 0.40688912 0.3997368  0.35922301 0.99055032\n",
      "  0.43717534 0.4406951  0.3592805  0.13538478]\n",
      " [0.41072931 0.46281713 0.78700844 0.32251138 0.48396987 0.43717534\n",
      "  1.1842511  0.63884983 0.46005749 0.39684808]\n",
      " [0.48340038 0.45007783 0.73639315 0.3882654  0.4438248  0.4406951\n",
      "  0.63884983 1.02853077 0.18347819 0.24403319]\n",
      " [0.41708394 0.39217987 0.50965012 0.49226217 0.36876735 0.3592805\n",
      "  0.46005749 0.18347819 0.90332919 0.42814801]\n",
      " [0.37812795 0.5739606  0.44175215 0.48038112 0.27045707 0.13538478\n",
      "  0.39684808 0.24403319 0.42814801 0.8597387 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import polar\n",
    "w, v = np.linalg.eig(B)\n",
    "U, H = polar(B)\n",
    "assert np.allclose(H, A2_eig)\n",
    "print(H, A2_eig)\n",
    "A2_eig = v.dot(np.diag(np.abs(w))).dot(v.T)\n",
    "B_pos = (B + A2_eig)/2\n",
    "is_pos_def(B_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = make_sparse_spd_matrix(dim=10, alpha=0.5)\n",
    "w, v = np.linalg.eig(A)\n",
    "A2_eig = v.dot(np.diag(np.abs(w))).dot(v.T)\n",
    "assert is_pos_def(A2_eig)\n",
    "print (A2_eig, A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_H(H, K=None, L=None, U=None,_rho=1, _mu=1):\n",
    "    return _rho/2* np.linalg.norm(L + U+ K.T.dot(np.linalg.inv(H).dot(K)))**2 + _mu*np.linalg.norm(H, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_lambda(lamda, H, K, L, U,  _rho, _mu, prox, grad, gamma, delta=1e-4, eps=0.9, max_iter=500):\n",
    "    \"\"\"Choose lambda for backtracking.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Salzo S. (2017). https://doi.org/10.1137/16M1073741\n",
    "\n",
    "    \"\"\"\n",
    "    lamda=1\n",
    "    partial_f = partial(objective_H,K=K, L=L, U=U, _rho=_rho, _mu=_mu)\n",
    "    fx = partial_f(H)\n",
    "\n",
    "    y_minus_x = prox - H\n",
    "    print(y_minus_x)\n",
    "    tolerance = _scalar_product(y_minus_x, grad)\n",
    "    #print(\"Tolerance:\", tolerance)\n",
    "    \n",
    "    tolerance += delta / gamma * _scalar_product(y_minus_x, y_minus_x)\n",
    "    #print(\"Tolerance:\", tolerance)\n",
    "    for i in range(max_iter):\n",
    "        # line-search\n",
    "        x1 = H + lamda * y_minus_x\n",
    "\n",
    "        loss_diff = partial_f(x1) - fx\n",
    "      #  print(\"Loss diff:\", loss_diff)\n",
    "        if loss_diff <= lamda * tolerance and is_pos_def(x1):\n",
    "              break\n",
    "        lamda *= eps\n",
    "    else:\n",
    "        print(\"nope lambda\")\n",
    "    return lamda, i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_gamma(H, _mu, grad, eps=0.9, max_iter=500):\n",
    "    \"\"\"Choose gamma for backtracking.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Salzo S. (2017). https://doi.org/10.1137/16M1073741\n",
    "\n",
    "    \"\"\"\n",
    "    gamma=1\n",
    "    for i in range(max_iter):\n",
    "        prox = soft_thresholding_od(H - gamma * grad, _mu * gamma)\n",
    "        if is_pos_def(prox):\n",
    "            print(\"cacca\")\n",
    "            break\n",
    "        gamma *= eps\n",
    "    else:\n",
    "        print(\"nope gamma\")\n",
    "    return gamma, prox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upgrade_H(L, K, U, _rho, _mu, verbose=0):\n",
    "    H = np.random.rand(K.shape[0], K.shape[0])\n",
    "    H = (H + H.T)/2\n",
    "    _lambda = 1\n",
    "    gamma = 1\n",
    "    obj = 1e+10\n",
    "    print(H.shape)\n",
    "    for iter_ in range(1000):\n",
    "        #print(H)\n",
    "        H_old = H\n",
    "        Hinv = np.linalg.inv(H)\n",
    "        gradient = -_rho* K.dot(L + U - np.linalg.multi_dot((K.T, Hinv, K))).dot(K.T).dot(Hinv).dot(Hinv)\n",
    "        #print(gradient)\n",
    "        gamma, _ = _choose_gamma(H, _mu, gradient)\n",
    "        print(gamma)\n",
    "        #gamma=1\n",
    "        Y = soft_thresholding_od(H - gamma*gradient, gamma*_mu)\n",
    "        #print(Y)\n",
    "        _lambda,_ = _choose_lambda(_lambda, H,K,L,U,_rho, _mu, Y, gradient, 1, max_iter=1000, delta=1e-2)\n",
    "        print(_lambda)\n",
    "        H = H + _lambda*(Y - H)\n",
    "        obj_old = obj\n",
    "        obj = objective_H(H, K, L, U,_rho=_rho, _mu=_mu)\n",
    "        obj_diff = obj_old - obj\n",
    "        iter_diff =np.linalg.norm(H - H_old) \n",
    "        if verbose:\n",
    "            print(\"Iter: %d, obj: %.5f, iter_diff: %.5f, obj_diff:%.10f\"%(iter_, obj, iter_diff, obj_diff))\n",
    "        if(obj_diff<1e-2 and iter_ > 50): \n",
    "            break\n",
    "    else:\n",
    "        print(\"Did not converge\")\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = per_cov\n",
    "H = np.random.rand(5,5)\n",
    "L = K.T.dot(np.linalg.pinv(H)).dot(K)\n",
    "U = np.zeros((10,10))\n",
    "H_found = _upgrade_H(L, K, U, 1,0.5, 1)\n",
    "H - H_found\n",
    "#print(H_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(emp_cov, K, R, T, H, mu, eta, rho):\n",
    "    res = fast_logdet(R)\n",
    "    res += np.sum(R*emp_cov)\n",
    "    res += rho/2 * np.linalg.norm(R - T + U + K.T.dot(np.linalg.inv(H)).dot(K))**2 \n",
    "    res += mu*np.linalg.norm(H,1)\n",
    "    res += eta*np.linalg.norm(T,1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_interlinks_graphical_lasso(X, K, mu=0.01, eta=0.01, rho=1., \n",
    "        tol=1e-3, rtol=1e-5, max_iter=100, verbose=False, return_n_iter=True,\n",
    "        return_history=False, compute_objective=False, compute_emp_cov=False,\n",
    "        random_state=None):\n",
    "    \n",
    "    random_state = check_random_state(random_state)\n",
    "    if compute_emp_cov:\n",
    "        n = X.shape[0] \n",
    "        emp_cov = empirical_covariance(X, assume_centered=False)\n",
    "    else:\n",
    "        emp_cov = X\n",
    "\n",
    "    H = np.random.rand(K.shape[0], K.shape[0])\n",
    "    H = H.T.dot(H)/2\n",
    "    T = emp_cov.copy()\n",
    "    T = (T + T.T)/2\n",
    "    R = T - np.linalg.multi_dot((K.T, np.linalg.pinv(H), K))\n",
    "    U = np.zeros((K.shape[1], K.shape[1]))\n",
    "    \n",
    "    checks = []\n",
    "    for iteration_ in range(max_iter):\n",
    "        R_old = R.copy()\n",
    "        \n",
    "        # R update\n",
    "        M = T - U - K.T.dot(np.linalg.pinv(H)).dot(K)\n",
    "        M = (M + M.T)/2\n",
    "        R = prox_logdet(emp_cov - rho*M, 1/rho)\n",
    "        assert is_pos_def(R), \"iter %d\"%iteration_\n",
    "        #print(\"----------------------R---------------------\\n\", R)\n",
    "        # T update\n",
    "        M = - R - U - K.T.dot(np.linalg.pinv(H)).dot(K)\n",
    "        M = (T + T.T)/2\n",
    "        T = soft_thresholding_od(M, eta/rho)\n",
    "        assert is_pos_def(T), \"teta iter %d\"%iteration_\n",
    "       \n",
    "        #print(\"----------------------T---------------------\\n\",T)\n",
    "        # H update\n",
    "        H = _upgrade_H(R, T, K, U, rho, mu)\n",
    "        assert(is_pos_def(H))\n",
    "        #print(\"----------------------H---------------------\\n\",H)\n",
    "        # U update\n",
    "        KHK = np.linalg.multi_dot((K.T, np.linalg.pinv(H), K))\n",
    "        assert is_pos_semi_def(KHK)\n",
    "        U += R - T + KHK\n",
    "\n",
    "        # diagnostics, reporting, termination checks\n",
    "        \n",
    "        obj = objective(emp_cov, K, R, T, H, mu, eta, rho) \\\n",
    "            if compute_objective else np.nan\n",
    "        rnorm = np.linalg.norm(R - T + KHK)\n",
    "        snorm = rho *np.linalg.norm(R - R_old)\n",
    "        check = convergence(\n",
    "            obj=obj, rnorm=rnorm, snorm=snorm,\n",
    "            e_pri=(np.sqrt(R.size) * tol + rtol *\n",
    "                   max(np.sqrt(np.linalg.norm(R)**2 + np.linalg.norm(U)**2),\n",
    "                       np.linalg.norm(T - KHK))),\n",
    "            e_dual=(np.sqrt(R.size) * tol + rtol * rho *\n",
    "                    np.linalg.norm(U))\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"obj: %.4f, rnorm: %.4f, snorm: %.4f,\"\n",
    "                  \"eps_pri: %.4f, eps_dual: %.4f\" % check)\n",
    "\n",
    "        checks.append(check)\n",
    "        if check.rnorm <= check.e_pri and check.snorm <= check.e_dual:\n",
    "            break\n",
    "        rho_new = update_rho(rho, rnorm, snorm, iteration=iteration_)\n",
    "        # scaled dual variables should be also rescaled\n",
    "        U *= rho / rho_new\n",
    "        rho = rho_new\n",
    "    else:\n",
    "        warnings.warn(\"Objective did not converge.\")\n",
    "\n",
    "    return_list = [R, T, H, emp_cov]\n",
    "    if return_n_iter:\n",
    "        return_list.append(iteration_)\n",
    "    if return_history:\n",
    "        return_list.append(checks)\n",
    "    return return_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fixed_interlinks_graphical_lasso(samples, per_cov, mu=1, eta=1, rho=1., \n",
    "        verbose=1, compute_objective=1, compute_emp_cov=1,\n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
