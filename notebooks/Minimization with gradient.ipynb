{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from six.moves import reload_module as reload\n",
    "from sklearn.utils.extmath import fast_logdet\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import make_sparse_spd_matrix\n",
    "from sklearn.covariance import empirical_covariance\n",
    "from functools import partial\n",
    "\n",
    "from network_inference.prox import prox_logdet, soft_thresholding_od\n",
    "import network_inference.datasets; reload(network_inference.datasets)\n",
    "from network_inference.datasets import is_pos_def, is_pos_semi_def\n",
    "from network_inference.utils import _scalar_product, update_rho, convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random_state=0\n",
    "A = make_sparse_spd_matrix(dim=15, alpha=0.7, random_state=random_state)\n",
    "\n",
    "T_true = A[5:,5:]\n",
    "K_true = A[10:,5:,]\n",
    "H_true = A[0:5,0:5]\n",
    "print(is_pos_def(H_true))\n",
    "per_cov = K_true*0.3\n",
    "T_obs = T_true - per_cov.T.dot(np.linalg.inv(H_true)).dot(per_cov)\n",
    "\n",
    "samples = np.random.multivariate_normal(np.zeros(10), np.linalg.inv(T_obs), 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import squared_norm\n",
    "from regain.norm import l1_od_norm\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_H(H, R=None, T=None, K=None, U= None,_rho=1, _mu=1):\n",
    "    if not is_pos_def(H):\n",
    "        return np.inf\n",
    "    return 0.5 * _rho * squared_norm(R - T + U + np.linalg.multi_dot((K.T, linalg.pinvh(H), K))) \\\n",
    "            + _mu * l1_od_norm(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_lambda(lamda, R, T, K, H, U,  _rho, _mu, prox, grad, gamma, delta=1e-4, eps=0.9, max_iter=500):\n",
    "    \"\"\"Choose lambda for backtracking.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Salzo S. (2017). https://doi.org/10.1137/16M1073741\n",
    "\n",
    "    \"\"\"\n",
    "    partial_f = partial(objective_H, R=R, T=T, K=K, U=U, _rho=_rho, _mu=_mu)\n",
    "    fx = partial_f(H)\n",
    "\n",
    "    y_minus_x = prox - H\n",
    "    tolerance = _scalar_product(y_minus_x, grad)\n",
    "    tolerance += delta / gamma * _scalar_product(y_minus_x, y_minus_x)\n",
    "    #print(\"Tolerance:\", tolerance)\n",
    "    for i in range(max_iter):\n",
    "        # line-search\n",
    "        x1 = H + lamda * y_minus_x\n",
    "\n",
    "        loss_diff = partial_f(x1) - fx\n",
    "        #print(\"Loss diff:\", loss_diff)\n",
    "        if loss_diff <= lamda * tolerance:\n",
    "              break\n",
    "        lamda *= eps\n",
    "    else:\n",
    "        return False, i+1\n",
    "    return lamda, i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_gamma(gamma, H, R, T, K, U, _rho, _mu, _lambda, grad,\n",
    "                 eps=0.9, max_iter=500):\n",
    "    \"\"\"Choose gamma for backtracking.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Salzo S. (2017). https://doi.org/10.1137/16M1073741\n",
    "\n",
    "    \"\"\"\n",
    "    partial_f = partial(objective_H, R=R, T=T, K=K, U=U, _rho=_rho, _mu=_mu)\n",
    "    fx = partial_f(H)\n",
    "    for i in range(max_iter):\n",
    "        prox = soft_thresholding_od(H - gamma * grad, _mu * gamma)\n",
    "        if is_pos_def(prox):\n",
    "            break\n",
    "        gamma *= eps\n",
    "    else:\n",
    "        print(\"not found gamma\")\n",
    "    return gamma, prox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upgrade_H(H, R, T, K, U, _rho, _mu, verbose=0, random_state=None):\n",
    "    # H = make_sparse_spd_matrix(dim=K.shape[0], alpha=0.5, random_state=random_state)\n",
    "    _lambda = 1\n",
    "    gamma = 1\n",
    "    obj = 1e+10\n",
    "    for iter_ in range(2000):\n",
    "        H_old = H.copy()\n",
    "        Hinv = linalg.pinvh(H)\n",
    "        gradient = - _rho * K.dot(R - T + U + np.linalg.multi_dot((K.T, Hinv, K))).dot(K.T).dot(Hinv).dot(Hinv)\n",
    "        gamma, _ = _choose_gamma(gamma, H, R, T, K, U, _rho,_mu, _lambda, gradient)\n",
    "        # print(gamma)\n",
    "        Y = soft_thresholding_od(H - gamma * gradient, gamma * _mu)\n",
    "        _lambda,_ = _choose_lambda(_lambda, R, T, K, H, U,_rho, _mu, Y, gradient, 1, max_iter=1000, delta=1e-2)\n",
    "\n",
    "        H = H + _lambda * (Y - H)\n",
    "        \n",
    "        obj_old = obj\n",
    "        obj = objective_H(H, R, T, K, U,_rho=_rho, _mu=_mu)\n",
    "        obj_diff = obj_old - obj\n",
    "        iter_diff =np.linalg.norm(H - H_old) \n",
    "        if verbose:\n",
    "            print(\"Iter: %d, obj: %.5f, iter_diff: %.5f, obj_diff:%.10f\"%(iter_, obj, iter_diff, obj_diff))\n",
    "        if(obj_diff<1e-4): \n",
    "            break\n",
    "    else:\n",
    "        print(\"Did not converge\")\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = np.random.rand(10,10)\n",
    "# T = np.random.rand(10,10)\n",
    "# U = np.zeros((10,10))\n",
    "# K = per_cov\n",
    "# H = make_sparse_spd_matrix(dim=K.shape[0], alpha=0.5)\n",
    "# R = T - K.T.dot(np.linalg.pinv(H)).dot(K)\n",
    "# H_found = _upgrade_H(R, T, K, U, 1,0.5, 1, random_state=0)\n",
    "# H - H_found, H, H_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(emp_cov, K, R, T, H, mu, eta, rho):\n",
    "    res = - fast_logdet(R) + np.sum(R * emp_cov)\n",
    "    res += rho / 2. * squared_norm(R - T + U + np.linalg.multi_dot((K.T, linalg.pinvh(H), K)))\n",
    "    res += mu * l1_od_norm(H)\n",
    "    res += eta * l1_od_norm(T)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_interlinks_graphical_lasso(X, K, mu=0.01, eta=0.01, rho=1., \n",
    "        tol=1e-3, rtol=1e-5, max_iter=100, verbose=False, return_n_iter=True,\n",
    "        return_history=False, compute_objective=False, compute_emp_cov=False,\n",
    "        random_state=None):\n",
    "    \n",
    "    random_state = check_random_state(random_state)\n",
    "    if compute_emp_cov:\n",
    "        n = X.shape[0] \n",
    "        emp_cov = empirical_covariance(X, assume_centered=False)\n",
    "    else:\n",
    "        emp_cov = X\n",
    "\n",
    "    # H = make_sparse_spd_matrix(K.shape[0], alpha=0.5)\n",
    "    H = np.eye(K.shape[0])\n",
    "    T = emp_cov.copy()\n",
    "    T = (T + T.T) / 2.\n",
    "    R = T - np.linalg.multi_dot((K.T, linalg.pinvh(H), K))\n",
    "    U = np.zeros((K.shape[1], K.shape[1]))\n",
    "    \n",
    "    checks = []\n",
    "    for iteration_ in range(max_iter):\n",
    "        R_old = R.copy()\n",
    "        \n",
    "        # R update\n",
    "        Hinv = linalg.pinvh(H)\n",
    "        M = T - U - K.T.dot(Hinv).dot(K)\n",
    "        M = (M + M.T)/2\n",
    "        R = prox_logdet(emp_cov - rho * M, 1. / rho)\n",
    "        assert is_pos_def(R), \"iter %d\"%iteration_\n",
    "        #print(\"----------------------R---------------------\\n\", R)\n",
    "        \n",
    "        # T update\n",
    "        M = R + U + K.T.dot(Hinv).dot(K)\n",
    "        M = (M + M.T) / 2.\n",
    "        # print(M)\n",
    "        T = soft_thresholding_od(M, eta / rho)\n",
    "        assert is_pos_def(T, tol=1e-8), \"teta iter %d\"%iteration_\n",
    "       \n",
    "        #print(\"----------------------T---------------------\\n\",T)\n",
    "        # H update\n",
    "        H = _upgrade_H(H, R, T, K, U, rho, mu, verbose=0)\n",
    "        assert(is_pos_def(H))\n",
    "        #print(\"----------------------H---------------------\\n\",H)\n",
    "        \n",
    "        # U update\n",
    "        KHK = np.linalg.multi_dot((K.T, linalg.pinvh(H), K))\n",
    "       # assert is_pos_semi_def(KHK)\n",
    "        U += R - T + KHK\n",
    "\n",
    "        # diagnostics, reporting, termination checks\n",
    "        \n",
    "        obj = objective(emp_cov, K, R, T, H, mu, eta, rho) \\\n",
    "            if compute_objective else np.nan\n",
    "        rnorm = np.linalg.norm(R - T + KHK)\n",
    "        snorm = rho * np.linalg.norm(R - R_old)\n",
    "        check = convergence(\n",
    "            obj=obj, rnorm=rnorm, snorm=snorm,\n",
    "            e_pri=(np.sqrt(R.size) * tol + rtol *\n",
    "                   max(np.linalg.norm(R),\n",
    "                       np.linalg.norm(T - KHK))),\n",
    "            e_dual=(np.sqrt(R.size) * tol + rtol * rho *\n",
    "                    np.linalg.norm(U))\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"obj: %.4f, rnorm: %.4f, snorm: %.4f,\"\n",
    "                  \"eps_pri: %.4f, eps_dual: %.4f\" % check)\n",
    "\n",
    "        checks.append(check)\n",
    "        if check.rnorm <= check.e_pri and check.snorm <= check.e_dual:\n",
    "            break\n",
    "        rho_new = update_rho(rho, rnorm, snorm, iteration=iteration_)\n",
    "        # scaled dual variables should be also rescaled\n",
    "        U *= rho / rho_new\n",
    "        rho = rho_new\n",
    "    else:\n",
    "        warnings.warn(\"Objective did not converge.\")\n",
    "\n",
    "    return_list = [R, T, H, emp_cov]\n",
    "    if return_n_iter:\n",
    "        return_list.append(iteration_)\n",
    "    if return_history:\n",
    "        return_list.append(checks)\n",
    "    return return_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj: 13.4987, rnorm: 0.3683, snorm: 3.6179,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 11.1296, rnorm: 1.0062, snorm: 1.0862,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 11.1274, rnorm: 0.6145, snorm: 0.4625,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 11.3102, rnorm: 0.4136, snorm: 0.2503,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 11.5045, rnorm: 0.2795, snorm: 0.1989,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 11.6839, rnorm: 0.1892, snorm: 0.1202,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 11.8161, rnorm: 0.1374, snorm: 0.0587,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 11.9141, rnorm: 0.1009, snorm: 0.0405,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 11.9857, rnorm: 0.0748, snorm: 0.0285,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 12.0372, rnorm: 0.0561, snorm: 0.0203,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 12.0744, rnorm: 0.0425, snorm: 0.0146,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 12.1011, rnorm: 0.0324, snorm: 0.0106,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 12.1203, rnorm: 0.0250, snorm: 0.0078,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 12.1342, rnorm: 0.0193, snorm: 0.0058,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 12.1443, rnorm: 0.0151, snorm: 0.0044,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 12.1518, rnorm: 0.0118, snorm: 0.0034,eps_pri: 0.0100, eps_dual: 0.0100\n",
      "obj: 12.1573, rnorm: 0.0092, snorm: 0.0026,eps_pri: 0.0100, eps_dual: 0.0100\n"
     ]
    }
   ],
   "source": [
    "res = fixed_interlinks_graphical_lasso(samples, per_cov, mu=1, eta=1, rho=1., \n",
    "        verbose=1, compute_objective=1, compute_emp_cov=1,\n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
